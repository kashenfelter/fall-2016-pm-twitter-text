---
title: "Dictionary methods"
author: Pablo Barbera (modified by RW)
date: May 19, 2016
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

#### Dictionary methods

A different type of keyword analysis consists on the application of dictionary methods, or lexicon-based approaches to the measurement of tone or the prediction of diferent categories related to the content of the text. 

The most common application is sentiment analysis: using a dictionary of positive and negative words, we compute a sentiment score for each individual document.

Let's apply this technique in the context of our running example.

```{r}
#set your personal working directory if you're running as chunks
#setwd("~/Dropbox/fall-2016-pm-twitter-text/")

tweets <- read.csv("../datasets/pres-tweets.csv", stringsAsFactors = F)
source('../functions.R')
```

```{r}
# loading lexicon of positive and negative words (from Neal Caren)
lexicon <- read.csv("../datasets/lexicon.csv", stringsAsFactors=F)
pos.words <- lexicon$word[lexicon$polarity=="positive"]
neg.words <- lexicon$word[lexicon$polarity=="negative"]
# a look at a random sample of positive and negative words
sample(pos.words, 10)
sample(neg.words, 10)
```

As earlier today, we will convert our text to a corpus object.

```{r}
#install.packages("quanteda")
library(quanteda)
twcorpus <- corpus(tweets$body)
```

Now we're ready to run the sentiment analysis!

```{r}
# first we construct a dictionary object
mydict <- dictionary(list(negative = neg.words,
                          positive = pos.words))
# apply it to our corpus
sent <- dfm(twcorpus, dictionary = mydict)
# and add it as a new variable
tweets$score <- as.numeric(sent[,2]) - as.numeric(sent[,1])
```

```{r}
# what is the average sentiment score?
mean(tweets$score)
# what is the most positive and most negative tweet?
tweets[which.max(tweets$score),]
tweets[which.min(tweets$score),]
# what is the proportion of positive, neutral, and negative tweets?
tweets$sentiment <- "neutral"
tweets$sentiment[tweets$score<0] <- "negative"
tweets$sentiment[tweets$score>0] <- "positive"

candidates <- c("Bernie Sanders","Hillary Clinton","Donald J. Trump", "Ted Cruz")

for (i in 1:4){
  print(candidates[i], row.names = F)
  print(table(tweets$sentiment[tweets$displayName == candidates[i]]), row.names = F)
}
```

We can also disaggregate by groups of tweets, for example according to the words they mention.

```{r}
words <- c("jobs", "terrorism", "establishment", "gun")

for (p in words){
  print(paste(p, " -- average sentiment: ",
      round(mean(tweets$score[grep(p, tweets$body, ignore.case=TRUE)]), 4)
    )
  )
}
```

